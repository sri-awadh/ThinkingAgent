diff --git a/reproduce_error.py b/reproduce_error.py
new file mode 100644
index 000000000..1158b812f
--- /dev/null
+++ b/reproduce_error.py
@@ -0,0 +1,21 @@
+import numpy as np
+from sklearn import linear_model as lm
+
+# Test database
+n = 100
+x = np.random.randn(n, 30)
+y = np.random.choice([0, 1], size=n)
+
+# Attempt to use store_cv_values parameter
+try:
+    rr = lm.RidgeClassifierCV(alphas=np.arange(0.1, 1000, 0.1), normalize=True,
+                              store_cv_values=True).fit(x, y)
+    print("RidgeClassifierCV executed successfully.")
+    if hasattr(rr, 'cv_values_'):
+        print("cv_values_ attribute is present.")
+    else:
+        print("cv_values_ attribute is missing.")
+except TypeError as e:
+    print(f"TypeError: {e}")
+except Exception as e:
+    print(f"Unexpected error: {e}")
\ No newline at end of file
diff --git a/sklearn/linear_model/ridge.py b/sklearn/linear_model/ridge.py
index 911c74ae3..a14ec92f9 100644
--- a/sklearn/linear_model/ridge.py
+++ b/sklearn/linear_model/ridge.py
@@ -1333,10 +1333,12 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):
     advantage of the multi-variate response support in Ridge.
     """
     def __init__(self, alphas=(0.1, 1.0, 10.0), fit_intercept=True,
-                 normalize=False, scoring=None, cv=None, class_weight=None):
+                 normalize=False, scoring=None, cv=None, class_weight=None,
+                 store_cv_values=False):
         super(RidgeClassifierCV, self).__init__(
             alphas=alphas, fit_intercept=fit_intercept, normalize=normalize,
-            scoring=scoring, cv=cv)
+            scoring=scoring, cv=cv, store_cv_values=store_cv_values)
+        self.store_cv_values = store_cv_values
         self.class_weight = class_weight

     def fit(self, X, y, sample_weight=None):
